# -*- coding: utf-8 -*-
"""loan_approval.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zramfcGzByYL0anmMbvl0-FM41s-9mg1

# IMPORTING DATA
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd

df=pd.read_csv('loan_data.csv')

df

"""# CLEANING DATA"""

def gender (a):
  if a=="male":
    return 1
  else:
    return 0

df['person_gender']= df['person_gender'].apply(gender)

df[['person_age','person_income' , 'loan_amnt' , 'cb_person_cred_hist_length']] = df[['person_age','person_income' , 'loan_amnt' , 'cb_person_cred_hist_length']].astype(int)

df.info()

# prompt: I wanna drop all rows that included in the column person_age over 75

df = df[df['person_age'] <= 75]

# prompt: saving the cvs file

df.to_csv('cleaned_loan_data.csv', index=False)
files.download('cleaned_loan_data.csv')

"""# VISUALIZATION"""

df=pd.read_csv('cleaned_loan_data.csv')

import matplotlib.pyplot as plt
import seaborn as sns

sns.boxplot(x='person_age', data=df)
plt.xticks(rotation= 45)

sns.pairplot(df)

sns.displot(x='loan_amnt', data=df, bins=10)
plt.xticks(rotation= 45)

sns.countplot(x='person_education', data=df)
plt.xticks(rotation= 45)

sns.scatterplot(x='credit_score', y='person_income', data= df, hue='person_education')

"""# FEATURING

"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error
import pickle

def previous_loan_defaults_on_file (a):
  if a=="Yes":
    return 1
  else:
    return 0

df['previous_loan_defaults_on_file'] = df['previous_loan_defaults_on_file'].apply(previous_loan_defaults_on_file)

df = pd.get_dummies(df, columns=['person_education', 'person_home_ownership', 'loan_intent',] , dtype=int)

# prompt: saving the cvs file

df.to_csv('featured.csv', index=False)
files.download('featured.csv')

"""# MODELIN (MACHINE LEARNING)"""

df.info()

x= df.drop('loan_status', axis=1)
y= df['loan_status']

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)

"""## Logistic Regression"""

from  sklearn.linear_model import LogisticRegression

lr=LogisticRegression()

lr.fit(x_train, y_train)

lr_prediction = lr.predict(x_test)

from sklearn.metrics import confusion_matrix

confusion_matrix(y_test,lr_prediction)

from sklearn.metrics import classification_report

print(classification_report(y_test,lr_prediction))

accuracy_score = lr.score(x_test, y_test)
print("Accuracy:", accuracy_score)

"""## K Nearest Neighbor (KNN)"""

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier()

knn.fit(x_train, y_train)

from sklearn.model_selection import GridSearchCV

param = {'n_neighbors': list(range(5, 51))}

knn_cv = GridSearchCV(knn, param)
knn_cv.fit(x_train, y_train)

print(knn_cv.best_params_)

knn_best = KNeighborsClassifier(n_neighbors=29)

knn_best.fit(x_train, y_train)

knn_best_predic = knn_best.predict(x_test)

accuracy_score = knn_best.score(x_test, y_test)
print("Accuracy:", accuracy_score)

"""## DecisionTree"""

from sklearn.tree import DecisionTreeClassifier

tree = DecisionTreeClassifier()

tree.fit(x_train, y_train)

tree_predic = tree.predict(x_test)

accuracy_score = tree.score(x_test, y_test)
print("Accuracy:", accuracy_score)

print(classification_report(y_test,tree_predic))

tree_1 = DecisionTreeClassifier()
print(tree_1.get_params())

param = {'max_depth': [1,5,7,15,29,31,51] ,
         'min_samples_split': [2,11,19,18,26,35,41,50] ,
         'min_samples_leaf': [1,3,5,7,11,19,27,33,46,50]}

tree_cv = GridSearchCV(tree_1, param)
tree_cv.fit(x_train, y_train)

print(tree_cv.best_params_)

best_tree = DecisionTreeClassifier(max_depth=15, min_samples_leaf=46, min_samples_split=2)

best_tree.fit(x_train, y_train)

accuracy_score = best_tree.score(x_test, y_test)
print("Accuracy:", accuracy_score)

"""## SVM"""

from sklearn.svm import SVC

svm = SVC()

svm.fit(x_train, y_train)

svm_predic = svm.predict(x_test)

accuracy_score = svm.score(x_test, y_test)
print("Accuracy:", accuracy_score)

print(classification_report(y_test,svm_predic))

resual = svm_predic - y_test

sns.distplot(resual,bins=50);



model_pk.predict(my_sample)

feature_names = model_pk.feature_names_in_
my_sample = my_sample[feature_names]

"""## Random Forest"""

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier()

rf.fit(x_train, y_train)

rf_predic = rf.predict(x_test)

accuracy_score = rf.score(x_test, y_test)
print("Accuracy:", accuracy_score)

print(classification_report(y_test,rf_predic))

import pickle

pickle.dump(rf, open('loan_approval_predict_RF.pkl' ,'wb'))

rf_1  = RandomForestClassifier()

rf_1.fit(x_train, y_train)

rf_1.get_params()

param = {'n_estimators': [1,5,7,15,29,31,51] ,
         'min_samples_split': [2,11,19,18,26,35,41,50] ,
         'min_samples_leaf': [1,3,5,7,11,19,27,33,46,50]}

rf_cv = GridSearchCV(rf_1, param)
rf_cv.fit(x_train, y_train)

print(rf_cv.best_params_)

best_rf = RandomForestClassifier(min_samples_split=19, n_estimators=51)

best_rf.fit(x_train, y_train)

accuracy_score = best_rf.score(x_test, y_test)
print("Accuracy:", accuracy_score)

my_sample = {'person_age': 24, 'person_gender': 0, 'person_income': 106670,
             'loan_amnt': 24000, 'loan_int_rate': 19, 'loan_percent_income': 0,
             'cb_person_cred_hist_length': 2,
             'credit_score': 657, 'person_emp_exp': 0,
             'previous_loan_defaults_on_file': 0,
             'person_education_Associate': 0, 'person_education_Bachelor': 1,
             'person_education_Doctorate': 0, 'person_education_High School': 0,
             'person_education_Master': 0, 'person_home_ownership_MORTGAGE': 0,
             'person_home_ownership_OTHER': 0, 'person_home_ownership_OWN': 0,
             'person_home_ownership_RENT': 0,
             'loan_intent_DEBTCONSOLIDATION': 0, 'loan_intent_EDUCATION':0,
             'loan_intent_HOMEIMPROVEMENT': 0, 'loan_intent_MEDICAL': 0,
             'loan_intent_PERSONAL': 0, 'loan_intent_VENTURE': 0}

model_pk = pickle.load(open('loan_approval_predict_RF.pkl','rb'))

my_sample = {key: [value] for key, value in my_sample.items()}
my_sample = pd.DataFrame(my_sample)

# Get the feature names the model was trained on
feature_names = model_pk.feature_names_in_

# Ensure my_sample has the same features and order
my_sample = my_sample[feature_names]

# Now you can make predictions
model_pk.predict(my_sample)